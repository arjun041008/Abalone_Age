# -*- coding: utf-8 -*-
"""Abalone_Age.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-3cZV1THGjB9YNReRhEIOmzqi-3rvOmU
"""

# Import Dictionaries

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
import tensorflow as tf
from keras.models import Sequential
from keras.layers import Dense
from sklearn.metrics import mean_absolute_error

import warnings
warnings.filterwarnings("ignore")

# Getting Dataset
df = pd.read_csv("/content/drive/MyDrive/abalone.csv")

# Printing Dataset
df.head(10)

# Changing Rings to age
df["Rings"] = df["Rings"] + 1.5
df = df.rename(columns = {"Rings" : "Age"})

# Information about DataFrame

df.info()

# Null and Duplicate Values

print(f"The number of null values is: ")
print(df.isnull().sum())
print(f"The number of duplicate values is {df.duplicated().sum()}")

# Lable Encoding
from sklearn.preprocessing import LabelEncoder
df["Sex"] = LabelEncoder().fit_transform(df["Sex"])

# Statistical Analysis

df.describe().drop("Sex" , axis = 1)

# Correlation
df1 = df.drop("Sex" , axis = 1)
plt.figure()
sns.heatmap(df1.corr() , annot = True)
plt.show()

plt.figure(figsize = (15 , 15))
sns.boxplot(df1)
plt.show()

#Removing Outliers
upper_range = df['Age'].quantile(0.90)
lower_range = df["Age"].quantile(0.1)

lower_range = np.array(lower_range)
upper_range = np.array(upper_range)

df = df[(df["Age"] > lower_range) & (df["Age"] < upper_range)]
df

plt.figure()
sns.boxplot(df["Age"])
plt.show()

plt.figure()
sns.pairplot(df1)
plt.show()

# Trianing and Testing DataFrames
Y = df["Age"]
df = df.drop("Age" , axis = 1)
X = df

xtrain , xtest , ytrain , ytest = train_test_split(X , Y , test_size = 0.2 , random_state = 45 )

# traing using Linear Regression
model = LinearRegression()
model.fit(xtrain , ytrain)

#evaluation
pred = model.predict(xtest)
print("The mean absolute error is " , mean_absolute_error(pred , ytest))

#training using random forest regressor
model1 = RandomForestRegressor()
model1.fit(xtrain , ytrain)

#evaluation
pred1 = model1.predict(xtest)
print("The mean absolute error is " , mean_absolute_error(pred1 , ytest))

#creating neural network
network = Sequential()
network.add(Dense(128 , activation = "relu" , input_shape = (xtrain.shape[1],)))
network.add(Dense(128 , activation = 'relu'))
network.add(Dense(128 , activation = 'relu'))
network.add(Dense(1 , activation = 'relu'))

# NN summary
network.summary()

#Compiling
network.compile(optimizer = "adam" , loss = 'mean_squared_error' , metrics = ['mae'])

#training NN
network.fit(xtrain , ytrain , epochs = 200 , batch_size = 32 , verbose = 1)

pred2 = network.predict(xtest)
print("The mean absolute error is " , mean_absolute_error(pred2 , ytest))